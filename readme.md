# ğŸ¬ ST-GCN4KeyFrames

A deep learning approach for video keyframe extraction using Spatial-Temporal Graph Convolutional Networks (ST-GCN).

## ğŸ“‹ Overview

This project implements an innovative method for automatic video keyframe selection by leveraging ST-GCN to model temporal relationships between video frames. The approach combines multiple feature types including optical flow, scene changes, facial expressions, and deep visual features to create a comprehensive representation of video content.

## âœ¨ Features

- **ğŸ¯ Multi-modal Feature Extraction**: Combines optical flow, scene change detection, facial geometry, and deep visual features
- **ğŸ•¸ï¸ Graph-based Modeling**: Uses ST-GCN to capture temporal dependencies between frames
- **ğŸ§  Intelligent Keyframe Selection**: Implements centrality, distinctiveness, and representativeness-based selection criteria
- **âš™ï¸ Configurable Parameters**: Easy-to-modify configuration for different use cases
- **âš¡ PyTorch Lightning Integration**: Clean, modular code structure with Lightning framework

## ğŸ—ï¸ Architecture

### ğŸ” Feature Extraction Pipeline

1. **â±ï¸ Temporal Features**: Frame indices and optical flow analysis
2. **ğŸ¨ Scene Analysis**: RGB histogram differences and SSIM-based scene change detection
3. **ğŸ‘¤ Facial Features**: Face geometry, expressions, and pose estimation using MediaPipe
4. **ğŸ¤– Deep Features**: Pre-trained CNN features with PCA dimensionality reduction

### ğŸ•¸ï¸ ST-GCN Model

- **ğŸ”— Graph Construction**: K-nearest neighbor adjacency matrix with temporal constraints
- **ğŸ§® Graph Convolution**: Multi-layer GCN with residual connections
- **ğŸ”€ Feature Fusion**: Combines all extracted features into unified representations

### ğŸ¯ Keyframe Selection Algorithm

The selection process considers three key factors:

- **â­ Centrality**: How well a frame represents the overall video content
- **ğŸ’ Distinctiveness**: How unique a frame is compared to others
- **ğŸ¯ Representativeness**: How well selected frames cover the entire video

## ğŸ“Š Keyframe Visualization

![Keyframe Extraction Process](assets/keyframes.png)

## ğŸš€ Installation

1. **ğŸ“¥ Clone the repository**:

```bash
git clone <repository-url>
cd ST-GCN4KeyFrames
```

2. **ğŸ Create a virtual environment**:

```bash
python -m venv stgcn-keyframes-env
source stgcn-keyframes-env/bin/activate  # On Windows: stgcn-keyframes-env\Scripts\activate
```

3. **ğŸ“¦ Install dependencies**:

```bash
pip install -r requirements.txt
```

## ğŸ’» Usage

### âš™ï¸ Configuration

Edit `config/config.yaml` to customize parameters:

```yaml
# Basic settings
video_dir: "./data/videos"      # Input video directory
output_dir: "./data/outputs"    # Output directory for keyframes
batch_size: 4
num_workers: 4
num_keyframes: 16              # Number of keyframes to extract

# ST-GCN model parameters
in_channels: 136               # Input feature dimension
hidden_channels: [256, 128, 64] # Hidden layer dimensions
num_layers: 3                  # Number of GCN layers

# Keyframe selection weights
centrality_weight: 0.4         # Weight for centrality score
distinctiveness_weight: 0.3    # Weight for distinctiveness score
representativeness_weight: 0.3 # Weight for representativeness score
coverage_threshold: 0.8        # Coverage threshold for early stopping

# Device configuration
device: "cuda:0"              # Use "cpu" for CPU-only processing
```

### ğŸ¬ Running Keyframe Extraction

1. **ğŸ“ Place your videos** in the `data/videos` directory
2. **â–¶ï¸ Run the extraction script**:

```bash
python test.py
```

The script will:

- ğŸ”„ Process all `.mp4` files in the input directory
- ğŸ” Extract comprehensive features from each frame
- ğŸ•¸ï¸ Apply ST-GCN to model temporal relationships
- ğŸ¯ Select optimal keyframes based on the configured criteria
- ğŸ’¾ Save selected keyframes as JPEG images in the output directory

### ğŸ“‚ Output Structure

```
data/outputs/
â”œâ”€â”€ video1/
â”‚   â”œâ”€â”€ keyframe_000.jpg
â”‚   â”œâ”€â”€ keyframe_015.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ video2/
â”‚   â”œâ”€â”€ keyframe_000.jpg
â”‚   â”œâ”€â”€ keyframe_012.jpg
â”‚   â””â”€â”€ ...
```

## ğŸ“ Project Structure

```
ST-GCN4KeyFrames/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml           # Configuration file
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ videos/              # Input video directory
â”‚   â””â”€â”€ outputs/             # Output keyframes directory
â”œâ”€â”€ lightning/
â”‚   â”œâ”€â”€ datamodule.py        # PyTorch Lightning data module
â”‚   â”œâ”€â”€ keyframe_selector.py # Keyframe selection algorithm
â”‚   â”œâ”€â”€ model.py             # ST-GCN model implementation
â”‚   â””â”€â”€ utils.py             # Utility functions
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ video_utils.py       # Video processing and feature extraction
â”œâ”€â”€ test.py                  # Main execution script
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ readme.md               # This file
```

## ğŸ“¦ Dependencies

- **âš¡ PyTorch Lightning**: Deep learning framework
- **ğŸ”¥ PyTorch**: Neural network library
- **ğŸ“¹ OpenCV**: Video processing
- **ğŸ‘¤ MediaPipe**: Face detection and landmark extraction
- **ğŸ”¬ scikit-learn**: Machine learning utilities
- **ğŸ–¼ï¸ scikit-image**: Image processing
- **ğŸ”¢ NumPy**: Numerical computing
- **ğŸ“Š Matplotlib**: Visualization

## ğŸ”§ Key Components

### ğŸ” Feature Extraction (`utils/video_utils.py`)

- **ğŸŒŠ Optical Flow**: Motion analysis between consecutive frames
- **ğŸ¨ Scene Change Detection**: RGB histogram differences and SSIM
- **ğŸ‘¤ Facial Analysis**: Face geometry, expressions, and pose estimation
- **ğŸ¤– Deep Features**: Pre-trained CNN features with PCA

### ğŸ•¸ï¸ ST-GCN Model (`lightning/model.py`)

- **ğŸ”— GraphConvBlock**: Residual graph convolution with batch normalization
- **ğŸ§  STGCN**: Main model combining multiple GCN layers

### ğŸ¯ Keyframe Selection (`lightning/keyframe_selector.py`)

- **â­ Centrality Computation**: Frame importance based on graph structure
- **ğŸ’ Distinctiveness**: Uniqueness measurement
- **ğŸ¯ Representativeness**: Coverage optimization
- **ğŸ”„ Greedy Selection**: Iterative frame selection algorithm

## âš¡ Performance Considerations

- **ğŸš€ GPU Acceleration**: Configure `device: "cuda:0"` for GPU processing
- **ğŸ’¾ Memory Usage**: Adjust `batch_size` and `max_frames` based on available memory
- **âš¡ Processing Speed**: Reduce `num_keyframes` for faster processing
- **ğŸ¯ Feature Quality**: Modify feature extraction parameters in `video_utils.py`

## ğŸ› ï¸ Customization

### â• Adding New Features

1. **ğŸ”§ Implement feature extraction function** in `utils/video_utils.py`
2. **ğŸ”„ Update `extract_features()`** to include new features
3. **ğŸ“Š Adjust `in_channels`** in configuration

### ğŸ¯ Modifying Selection Criteria

1. **âš–ï¸ Edit weights** in `config.yaml`
2. **ğŸ§® Modify selection algorithm** in `lightning/keyframe_selector.py`
3. **â• Add new scoring functions** as needed

### ğŸ—ï¸ Model Architecture Changes

1. **ğŸ”§ Modify `lightning/model.py`** for different GCN architectures
2. **ğŸ“Š Adjust `hidden_channels` and `num_layers`** in configuration

## ğŸ“„ License

[Add your license information here]

## ğŸ“š Citation

If you use this code in your research, please cite:

```bibtex
[Add citation information here]
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ Contact

[Add your contact information here]
